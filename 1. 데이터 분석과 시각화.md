# 1. 데이터 분석과 시각화 정리

교재에서 배웠던 내pl용들을 정리합니다.



## pandas 추가 명령어

#### 데이터 표현 및 그리기

```python
import pandas as pd

%matplotlib inline  # 'matplotlib'을 이용하여 시각화한 결과를 jupyter notebook에서 바로 볼 수 있게 하는 명령어입니다. 다만 안 써도 돌아가는걸 확인할 수 있었습니다.
#화장품 설문조사 파일을 불러옵니다.
df = pd.read_csv('cosmetics_.csv')
df_amount = df['amount']

df['gender'].value_counts().plot(kind = 'pie')  # gender 비율을 pie 차트로 나타냅니다. 또한 bar로 막대그래프로 나타낼 수 있습니다. output : 원형그래프
df.hist(bins = 50, figsize=(20, 15)) # output : 각 변수에 맞는 막대그래프

# seaborn으로 그리기
import seaborn as sns  # seaborn 패키지로 그리기
sns.distplot(df_amount, rug = True)  # amount와 count간 산점도/분포 그려보기
sns.jointplot(x = 'amount', y = 'count', data = df)
sns.jointplot(x='amount',y='count',data=df,kind='kde',space= 0, zorder = 0, n_levels=6)
```

#### 데이터의 이상치 제거

```python
# IQR 기준 이상치 제거
df.quantile()
Q1 = df['amount'].qunatile(q=0.25)
Q3 = df['amount'].quantile(q=0.75)
IQR = Q3 - Q1
df[(df['amount'] < Q3 + IQR * 1.5) & (df['amount'] > Q1 - IQR * 1.5)]

#상자수염도표로 양상 확인하기
df.boxplot(column = 'count', return_type = 'both')
df.boxplot(column = 'amount', return_type = 'both')


# 연구자 기준 이상치 제거
ndf = df.filter(['amount', 'count'])
ndf = ndf[(ndf['count'] < 10) & (ndf['amount'] < 500000)]
ndf.hist(bins = 50, figsize = (20, 15))

# seaborn으로 확인
sns.jointplot(x = 'amount', y = 'count', data = ndf)
sns.jointplot(x = 'amount',y = 'count',data = ndf, kind='kde', space=0, zorder= 0, n_levels = 6)

# 너무 한쪽으로 쏠려 있다고 생각이 들면 log변환후 획인합니다.
import numpy as np
ndf['logamount'] = np.log(ndf['amount'])
#numpy를 사용하여 map처럼 알맞은 각각의 값을 불러올 수 있습니다.
sns.jointplot(x = 'logamount', y = 'count', data=ndf, kind='kde', space=0, zorder=0, n_levels = 6)
```



## 자료 유형

#### 범주형 자료(질적 자료)

범주형 자료는 연속적이지 않은 자료라고 할 수 있다. 수를 잘 이용하지 않는다. 범주형 자료는 빈도분석을 이용한다.

##### 명목 척도

단순히 분류할 목적으로 숫자를 부여합니다.

성별, 결혼여부, 직업,  인지 브랜드,  구매 동기, 구매 성향, 피부 타입, 선호 프로모션, 구매 장소가 있습니다.

##### 서열 척도

순서/서열적 의미 즉 높고 낮음이 드러나는 척도입니다.

학력, 월소득이 있습니다.



#### 연속형 자료(양적 자료)

연속형 자료는 연속적이고 양적인 부분이 보인다고 할 수 있다. 수를 통해 데이터를 자주 나타낸다. 연속형 자료는 기술통계를 이용한다.

##### 등간척도

순서 뿐만이 아니라 숫자의 간격이 동일해 양적인 정도를 알 수 있는 척도

구매가격 만족, 구매문의 만족, 전반만족도, 재구매의향이 있다.

##### 비율 척도

등간척도에다가 수치가 0이면 의미가 '없다'를 담음

연구매횟수, 1회구매비용이 있다.



### 자료유형을 통한 분석방법

| 척도와 분석간의 관계. | .               | 독립변수...      | ...                        |
| :-------------------: | --------------- | :--------------- | -------------------------- |
|           .           | .               | **범주형 자료**  | **연속형 자료**            |
|    **종속변수.**.     | **범주형 자료** | 교차분석         | 로지스틱 회귀분석          |
|          ..           | **연속형 자료** | t-test, 분산분석 | 상관관계분석, 선형회귀분석 |



## 1 교차분석

독립변수와 종속변수가 모두 범주형 자료일 때 사용하는 분석법. 두 변수간의 상호관련성을 알아보고자 할 때 사용합니다.

#### 이론적인 방법

검정 통계량과 자유도를 비교합니다. 검정 통계량은 범주형 자료라서 독립적이라고 가정했을 때 50%씩 배분된다고 할 수 있고, 원 데이터랑 차이의 정도를 분석합니다. 그 값을 카이제곱이라고 하고 자유도와 비교하여 유의확률을 알아냅니다.

#### 파이썬으로 나타내기

화장품 구매 성향과 피부타입에 대한 상관관계를 분석하려면 교차분석을 하면 된다.

```python
import pandas as pd
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
from scipy.stats import chisquare
chisquare(df.propensity, df.skin)

# statistic=291.8166666666667, pvalue=0.023890557260065975)
```

pvalue를 통해 귀무가설일 확률은 2%라는 것을 알 수 있다. **전체 모집단에서도 화장품 구매 성향과 피부 타입에 대한 상관관계가 있을 것이라고 생각 할 수 있습니다.**  만일모든 데이터의 값이 같았다면 statistic = 0, pvalue = 1이 나왔을 것입니다.

```Python
chisquare(df.gender, df.marriage)
# statistic=78.5, pvalue=1.0 성별과 결혼여부는 전혀 관련이 없습니다.

chisquare(df.gender, df.job)
# statistic=561.9619047619046, pvalue=9.137938543046456e-27 성별과 직업간에 관련이 있습니다.

chisquare(df.gender, df.aware)
# statistic=491.53724383260703,pvalue=1.6154892387218957e-18 성별과 인지브랜드간에 관련이 있습니다.

chisquare(df.decision, df.propensity)
# statistic=199.83333333333334, pvalue=0.9860048055043245 구매 동기와 구매 성향간에 관련은 없습니다.
```

### 분석결과의 시각화

#### matplot를 이용하여 표현하기

```python
df['propensity'] = df['propensity'].replace([1,2,3], ['low cost', 'middle cost', 'high cost'])  # 필요한 부분이 있으면 이렇게 이름을 바꾸면 됩니다.

ct = pd.crosstab(df.propensity, df.skin, margins = True)
ct.plot.bar(stacked = True)
```

#### seaborn를 이용하여 표현하기

```python
import seaborn as sns
stacked = ct.stack().reset_index().rename(columns = {0:'value'})
sns.barplot(x = stacked.propensity, y = stacked.value, hue = stacked.skin)
```



## 2.1 독립표본 t-test

독립변수가 범주형이고 종속변수가 연속형 자료일때 사용합니다. 특히 독립표본 t-test는 독립변수가 2개일 때 하나의 종속변수의 평균이 동일한가를 검증합니다.

#### 이론적인 방법

t-value 값은 두 평균의 차이를 표준오차로 나눈 값이고, t-value값을 통해서 z값처럼 %로 환산해 확인해봅니다. 예를 들어 t-value 값이 1.96 이면 95% 확률로 상관관계가 있다고 볼 수 있습니다. 일반적으로 등분산이 충족되어야 합니다.

이때 표준오차는 다음과 같습니다.
$$
\frac{1}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}
$$
등분산이 충족되지 않을때, 복잡한 수식의 표준오차를 사용하게 됩니다.

#### 파이썬으로 나타내기

성별과 전반만족도에 대한 상관관계를 알아보려면 독립표본 t-test를 이용하면 됩니다.

```python
import pandas as pd
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
import scipy as sp
from scipy import stats

male = df[df['gender']==1].satisf_al.values  # 남자의 모든 전반만족도 데이터를 가지고옴
female = df[df['gender']==2].satisf_al.values  # 여자의 모든 전반만족도 데이더를 가지고옴
sp.stats.levene(male, female)  # 등분산인지 판별합니다.
stats.ttest_ind(male, female, equal_var = True)  # 등분산이라 보고 독립 t-test를 진행
```

statistic=0.1004969602960224, pvalue=0.7515040456669715 두 집단의 분산의 차이가 없을 확률이 75%이기 때문에 t-test 사용하기에 적절하다고 할 수 있습니다.

statistic=-0.494589803056421, pvalue=0.6213329051985961 조사된 남자와 여자의 전반적 만족도 차이가 나지 않습니다. **따라서 전체 모집단에서도 성별에 따른 전반만족도의 차이가 없을 것입니다.**

등분산이 아니고 이분산이 될 때에는 (levene의 pvalue값이 0.05보다 작으면) equal_var = False를 사용합니다.

```Python
sp.stats.levene(married, notMarried)
stats.ttest_ind(married, notMarried, equal_var = False)
# statistic=4.440258478441038, pvalue=0.036117599338368445
# statistic=1.4033327624432177, pvalue=0.1637027257549983
# 결혼 유무에 따른 전반만족도를 조사해보았습니다. 등분산인지 조사해보았더니 분산의 차이가 없을 확률이 작기 때문에(분산의 차이가 큼) equal_var = False로 합니다. 독립 t-test를 한 결과 0.16이 나왔으므로 유의하지는 않으나 꼭 그런건 아니라는 결과가 나왔습니다. (결혼한 집단에서 조금 더 만족을 했다고 볼 수 있습니다.)
```

###  분석결과의 시각화

#### 상자수염도표로 양상 확인하기

```python
import matplotlib.pyplot as plt
plt.boxplot((male, female))

df.boxplot(cloumn = 'satisf_al', by = 'gender')
```

#### seaborn을 이용한 집단별 분포 시각화

```python
import seaborn as sns

sns.distplot(male, kde = False, hist_kws = {'color':'r', 'alpha':0.2}, fit_kws={'color':'r'}, label = 'Social', fit = sp.stats.norm)
sns.distplot(female, kde = False, hist_kws = {'color':'g', 'alpha':0.2}, fit_kws={'color':'r'}, label = 'Psy', fit = sp.stats.norm)
```



## 2.2 대응표본 t-test

독립변수가 범주형이고 종속변수가 연속형 자료일때 사용합니다. 독립표본 t-test와 달리 대응표본 t-test는 두 변수간에 특정한 관련이 있을 때 사용하는 것입니다. 예를 들어, 사전점수-사후점수, 중간고사-기말고사, 만족도-중요도 등이 해당됩니다.

### 이론적인 방법

독립표본 t-test와 다 같지만 나누어주는 표준오차의 값이 다릅니다.

표준오차의 값은 다음과 같습니다.
$$
\frac{1}{\frac{s_d}{\sqrt{n}}}
$$

### 파이썬으로 나타내기

구매 가격만족과 구매 문의만족에 대한 상관관계를 알아보려면 대응표본 t-test를 사용하면 된니다.

 ```Python
import pandas as pd
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
import scipy as sp
from scipy import stats

stats.ttest_rel(df.satisf_b, df.satisf_i)
 ```

statistic=-7.155916401026872, pvalue=9.518854506666398e-12 구매 가격 만족과 구매 문의만족에 대한 관계가 없을 확률이 0%입니다. 이는 **구매 가격만족을 하면 구매 문의만족을 하거나 구매 문의만족을 하면 구매 가격만족을 한다는 것을 알 수 있습니다.**

```python
stats.ttest_rel(df.satisf_b, satisf_al)
# statistic=-8.144391819123236, pvalue=1.921108526180966e-14
# 구매가격 만족과 전반만족도는 유의하다고 볼 수 있습니다.
```

### 분석결과의 시각화

#### seaborn을 이용한 집단별 분포 시각화

```python
import seaborn as sns
sns.distplot(df['satisf_b'], color = 'skyblue', label = 'price Satisfaction')
sns.distplot(df['satisf_i'], color = 'red', label = 'Query Satisfaction')
```



## 3. 분산분석

독립변수가 범주형이고 종속변수가 연속형 자료일때 사용합니다.  t-test와 달리 분산분석은 세 집단(또는 그 이상) 간의 평균차이를 분석합니다.

#### 이론적인 방법

집단간 분산을 구하여 모두 더합니다. 각 데이터에 맞는 평균과 평균 데이터의 평균을 비교하여 차이와 분산을 가져옵니다. 이를 자유도(r-1)로 나눕니다.

두번째로 집단 내 분산을 구한다. 각 데이터의 평균과 원 데이터의 차를 제곱하여 더합니다. 이를 모두 합하고 자유도(N-r)로 나눕니다.

집단간 분산을 집단내 분산으로 나눈 값을 F-value입니다.

알파=0.05 표에서 자유도(r-1)과 자유도(N-r)를 찾고, 그에 해당하는 값이 F-value보다 작으면 유의하다고 합니다.

#### 파이썬으로 나타내기

구매동기와 전반만족도로 분산분석을 수행합니다.

```Python
import pandas as pd
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
import scipy as sp
from scipy import stats

anova = []
for i in range(3):
    anova.append(df[df['decision'] == i + 1].satisf_al.values)
stats.f_oneway(anova[0], anova[1], anova[2])
```

statistic=4.732129410493065, pvalue=0.009632034309915485 이는 귀무가설은 채택되지 않고, **구매동기와 전반만족도 사이의 관계는 유의하다고 할 수 있습니다.**



집단 간 차이를 비교하기 위해 사후검정을 하여 자세히 알아보려고 합니다.

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(endog=df['satisf_al'], groups = df['decision'], alpha = 0.05)
tukey.summary()
fig = tukey.plot_simultaneous()
```

group1과 group3 True값이 나오는데, 사회적 요인이나 외모적 요인으로 인한 구매만족도 차이가 있다는 것을 알 수 있습니다.

### 분석결과의 시각화

#### 상자수염도표로 양상 확인하기

```python
import matplotlib.pyplot as plt
plt.boxplot((anova[0], anova[1], anova[2]))

df.boxplot(column = 'satisf_al', by = 'decision')
```

#### seaborn을 이용한 집단별 분포 시각화

```python
import seaborn as sns

sns.distplot(anova[0], kde = False, hist_kws = {'color':'r', 'alpha':0.2}, fit_kws = {'color':'r'}, label='Social', fit = sp.stats.norm)
sns.distplot(anova[1], kde = False, hist_kws = {'color':'g', 'alpha':0.2}, fit_kws = {'color':'g'}, label='psy', fit = sp.stats.norm)
sns.distplot(anova[2], kde = False, hist_kws = {'color':'b', 'alpha':0.2}, fit_kws = {'color':'b'}, label='look', fit = sp.stats.norm)
```



## 4. 상관관계분석

독립변수, 종속변수 모두 연속형 자료일 때, 두 변수 간의 상관 정도를 파악하는 분석 방법입니다.

#### 이론적인 방법

두 데이터에 대한 축을 지정하여 중심이 되는 값을 잡아 원 데이터에 대한 각각의 차이를 곱하여 다 더합니다. 이를 (n-1)로 나누어 공분산의 합을 구합니다.

각각 두 데이터의 표준편차를 구하여 공분산에다가 나누어줍니다. 그 값은 t-value인데 1.96이상 넘어가면 95%이상의 확률로 유의하다고 합니다.

#### 파이썬으로 나타내기

```python
import pandas as pd
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
import scipy as sp
from scipy import stats

df.corr(method = 'pearson')  # kendall, spearman이 있다 이는 변수들이 서열척도일 때 사용합니다.
```

이렇게 하면 모든 데이터값이 나오는데(엄청나게 많아요!), 연속형 자료에 해당하는 필요한 값만 비교하면 됩니다. 전반만족도와 재구매의향에 대한 유의한 확률이 0.56이 나왔으므로 **전체 모집단에서도 전반만족도와 재구매의향에 대한 관계가 유의하다고 볼 수 있습니다.**

### 분석결과의 시각화

```python
import matplotlib.pyplot as plt
import seaborn as sns
sns.pairplot(df)

# 일부 변수만 가지고 오려면 다음과 같이 하면 됩니다
df_corr = df[['decision', 'satisf_b', 'satisf_i', 'satisf_al', 'repurchase']]
sns.pairplot(df_corr, diag_kind = 'kde')
sns.pairplot(df_corr, diag_kind="hist")
sns.pairplot(df_corr, diag_kind="kde", diag_kws=dict(shade=True, bw=.05, vertical=False) )
sns.pairplot(df_corr, kind="scatter", hue="decision", markers=["o", "s", "D"], palette="Set2")
sns.pairplot(df_corr, kind="scatter", hue="decision", plot_kws=dict(s=80, edgecolor="white", linewidth=2.5))
```



## 5. 선형회귀분석

연속형 독립변수가 연속형 종속변수에 영향을 미치는지를 파악하기 위한 분석법.

독립 -> 종속이 영향관계가 성립되는지에 대해 중요하고, 영향과 예측 이 두가지 목적이 가장 중요합니다.

회귀분석에 사용된 함수식이 종속변수에 영향을 미친다고 생각되는 독립변수를 모두 포함하고 있어야 합니다.

#### 이론적인 방법

최소제곱법에 사용되는 회귀계수를 통하여 최소로 할 수 있는 회귀식을 찾고 회귀계수를 구합니다. 이를 통하여서 설명이 잘 되었는지 확인합니다.

#### 파이썬으로 나타내기

구매문의만족과 재구매의향간 선형회귀분석으로 확인합니다.

```python
import statsmodels.api as sm
import statsmodels.formula.api as smf

#단일 선형회귀분석
linear_model = smf.ols(formula = 'repurchase ~ satisf_i', data = df).fit()

#다중 선형회귀분석
multiple_model = smf.ols(formula = 'repurchase ~ satisf_i + satisf_b', data = df).fit()
```

R-squared가 높으면 독립변수가 종속변수를 잘 설명했다고 볼 수 있습니다. Adj R-squared랑 값이 비슷해야 격차가 적어 잘 설명했다고 할 수 있습니다. Prob값이 작으면 모델 자체가 유의하다고 할 수 있습니다.

단일 선형회귀분석에서 satisf_i값의 Coef.값은 선형회귀모델의 기울기고 intercept의 coef.값은 y절편이라고 볼 수 있습니다. P > ltl 값이 귀무가설일 확률을 나타내고 있습니다. 0.05보다 적어야 유의하다고 할 수 있습니다.

다중 선형회귀분석에서 P > ltl 값이 크게 나오면 귀무가설이 채댁하게 됩니다.

### 분석결과의 시각화

```python
#선형성 및 등분산성 진단
import matplotlib.pyplot as plt
residsvfitted = plt.plot(Ndf['fitted'], Ndf['resids'], 'o')
I = plt.axhline(y=0, color = 'grey', linestyle = 'dashed')
plt.xlabel('Fitted values')
plt.ylabel('Residuals')
plt.title('Residuals vs Fitted')
plt.show(residsvfitted)

#선형성 및 등분산성 진단
qqplot = sm.qqplot(Ndf['std_resids'], line='s')
plt.show(qqplot)

scalelocplot = plt.plot(Ndf['fitted'], abs(Ndf['std_resids']) ** 5, 'o')
plt.xlabel('Fitted values')
plt.ylabel('Square Root of |standardized residuals|')
plt.show(scalelocplot)

residvlevplot = sm.graphics.influence_plot(multi_linear, criterion = 'Cooks', size = 2)
plt.show(residsvlevplot)
```





## 6. 더미회귀분석

더미회귀분석이란 선형회귀분석과 비슷하지만, 선형회귀분석과 달리 더미회귀분석에는 코딩된 숫자의 의미(기혼 = 1, 미혼 = 2)는 없애고 특정 범주에 해당되는지의 여부(미혼 = 1, 기혼 = 0)의 개념이 들어간 더미변수가 있습니다. 범주형 자료를 연속형 자료로 만들어주는 역할을 합니다. (참고로 머신러닝, 딥러닝에서는 이를 One-hot-encoding이라고 합니다.) 이때 통제변수는 항상 같아야 합니다.

#### 이론적인 방법

더미변수를 만들어서 선형회귀분석처럼 하면 됩니다. 더미변수는 (집단수 - 1)개를 만들면 됩니다.

#### 파이썬으로 나타내기

이번에는  satisf_b + satisf_i + gender + decision이 재구매의향에 미치는 영향에 대해서 알아볼 것입니다. 범주형 독립변수는 C(범주형 자료)로 해야 더미변수화가 됩니다.

```Python
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')
dum_linear = smf.ols(formula='repurchase ~ satisf_b + satisf_i + C(gender) + C(decision)', data = df).fit()
```

재구매의향(y) = 0.4252 X 문의만족 + 0.1739 X 성별 + ... + 1.9445 이라고 할 수 있습니다.

P > ltl 가 0.05보다 높은 값은 재구매의향에 대한 값에 대해 유의하지 않다는 것을 알 수 있습니다.

### 분석결과의 시각화

교재 자료는 없습니다만 선형회귀분석에서 했던 것처럼 하면 됩니다.



## 7. 로지스틱 회귀분석

선형성을 가지고 있지 않은 그래프에서 파악해볼 수 있는 회귀분석방법 입니다.

#### 이론적인 방법

로지스틱 회귀식을 통해 로지스틱 회귀 모델을 가져온다. 어떤 값이 1 증가할 때, e의 y제곱 배 증가하는걸 확인할 수 있다. 그 식을 얼마나 잘 설명했는지에 대한 유의도도 조사합니다.

#### 파이썬으로 나타내기

```python
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
df = pd.read_csv('cosmetics_.csv', encoding = 'utf-8')

#범주형 자료를 연속형으로 바꿉니다.
df['repurchase_re'] = df['repurchase'].replace([1,2,3,4,5], [0,0,0,1,1])
logit_model = smf.logit(formula = 'repurchase_re ~ satisf_al + C(propensity) + C(decision)', data = df).fit()

#회귀계수의 신뢰구간 추정
logit_model.conf_int()

#회귀계수의 승산(exp)와 오즈비의 해석
np.exp(logit_model.params)

#오즈비의 신뢰구간
params = logit_model.params
conf = logit_model.conf_int()
conf['OR'] = params
conf.colums = ['2.5%', '97.5', 'OR']
np.exp(conf)

#각 케이스별 종속변수 예측확률 병합하기
predict = pd.DataFrame({'predict':logit_model.predict()})
df = pd.concat([df, predict], axis = 1)

#예측 확률 0.5기준 예측그룹 생성하기
def pre_groups(series):
    if series < 0.5:
        return 0
    else series >= 0.5:
        return 1

df['preGroup'] = df['predict'].apply(pre_groups)

# 예측력 분석
pd.crosstab(df.repurchase_re, df.preGroup, margins = True)
```



### 분석결과의 시각화

여기 역시 교재 자료가 없습니다만 선형회귀 분석에서 사용했던 것을 쓰면 됩니다.